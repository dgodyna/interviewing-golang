# Introduction

This repository contains sample programs created for interview purposes. These programs operate according to the design
specifications detailed below and produce correct results. However, the current implementation is neither optimized nor
efficient, as it suffers from performance bottlenecks and potential vulnerabilities.

The primary objective of this project is to refactor and improve the code to enhance its performance, address
vulnerabilities, and ensure the system is efficient, maintainable, and scalable.

# Rules

You can use any tools or resources needed to work with the code. Treat this as a real-world task; you are allowed to
utilize the following:

* Any IDE (e.g., GoLand, VS Code, Cursor, etc.);
* Search engines (e.g., Google);
* AI Assistants (e.g., Copilot, JetBrains AI Assistant, ChatGPT, etc.);
* Asking questions to the interviewers.

# Description

## Task Background

The goal of this project is to develop a system to handle the **rating of network events**. These events are captured by
a mediation system, which processes hundreds of thousands of events per second. The mediation system’s sole purpose is
to persist these events on disk for further processing.

Once a week, the persisted events are transferred to a **rating system**, which reads them from storage and performs
rating operations. The system operates under a strict **two-hour time window**, making the execution time of each
operation critical to success.

### Objectives:

1. Design a mechanism to generate millions of events and persist them on disk, mimicking the behavior of the mediation
   system for internal testing purposes.
2. Implement an efficient mechanism to load the persisted events into a database, preparing them for rating.

---

## System Description

The system is divided into two main components: **data generator** and **data loader**.

**Note**: While the event format contract between the generator and loader can be modified, the database table schema
must remain unchanged.

### Data Generator

The **data generator** is responsible for generating a specified number of **random events**. Each event’s content is
randomly generated, and while uniqueness is not enforced, constants or identical values across events should be avoided.

The most important field in the generated data is the `event_type`. Based on its value, the rating system performs
specific actions, which have varying resource costs. The generator ensures that events are generated with the following
probabilities for each event type:

- **Event type '1'**: 15%
- **Event type '2'**: 20%
- **Event type '3'**: 20%
- **Event type '5'**: 45%

The resulting events are stored locally on the file system for future processing. The event structure generated by the
data generator matches the schema of the database table to ensure compatibility with the loader.

### Data Loader

The **data loader** is a separate process that reads the event data files produced by the generator and inserts the
events into the database. The insertion process must be optimized to handle large volumes of generated data efficiently.

---

### Database Table Structure

The system uses the following database schema for storing events:

```sql
CREATE TABLE event (
    event_source     TEXT NOT NULL, -- Unique identifier of the client
    event_ref        TEXT NOT NULL, -- Unique identifier of the event
    event_type       INTEGER NOT NULL,
    event_date       TIMESTAMP NOT NULL,
    calling_number   BIGINT NOT NULL,
    called_number    BIGINT NOT NULL,
    location         TEXT NOT NULL,
    duration_seconds BIGINT NOT NULL,
    attr_1           TEXT,
    attr_2           TEXT,
    attr_3           TEXT,
    attr_4           TEXT,
    attr_5           TEXT,
    attr_6           TEXT,
    attr_7           TEXT,
    attr_8           TEXT,
    PRIMARY KEY (event_source, event_ref)
);

CREATE INDEX event_called_number_index     ON event (called_number);
CREATE INDEX event_calling_number_index    ON event (calling_number);
CREATE INDEX event_event_date_index        ON event (event_date);
CREATE UNIQUE INDEX event_event_ref_uindex ON event (event_ref);
CREATE INDEX event_event_type_index        ON event (event_type);
CREATE INDEX event_location_index          ON event (location);
```

This schema is designed to allow fast lookups based on key query parameters, including `event_ref`, `called_number`,
`calling_number`, `event_date`, `event_type`, and `location`.

---

## Goal

Our ultimate goal is to **generate and insert 1 billion events** into the database efficiently.

To validate the system, you can perform testing on a smaller scale using the following steps:

1. Start the PostgreSQL instance:
   ```shell
   make start_env
   ```

2. Run the test for generating and inserting 1 million events:
   ```shell
   make test_1M
   ```

---

This documentation provides a clear and structured overview of the project, its objectives, and implementation
specifics.